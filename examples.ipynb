{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e25d74-23a1-45db-9637-6a44b30c7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapeai import Folder, AnthropicClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ad4da-d673-49d8-b8eb-60a690dfe5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AnthropicClient(api_key='zzz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45feac67-cee3-4ca8-acda-9649bde578ba",
   "metadata": {},
   "source": [
    "# Answering questions about random text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacc90c3-000f-4f82-a4c7-f4c2e0276fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Folder(path='./example_collection', files_endwith=['.txt'], client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7720bc7-2e70-47e3-b20f-c8efe15308d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c.txt', 'e.txt', 'd.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e81026e-8687-4743-98db-8d061c28e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.txt\n",
      "Title: A treatise on the uses of native shrubbery and the children there into.\n",
      "By: Thomas Babington the Third\n",
      "Well by this point, I would say that's about all there is to say on the subject.\n",
      "\n",
      "e.txt\n",
      "Okay.\n",
      "\n",
      "d.txt\n",
      "Another Exciting Story\n",
      "By Anon\n",
      "\n",
      "Once upon anon anon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in folder.get_files():\n",
    "    print(f.path.name)\n",
    "    print(f.content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca8d1ec-b008-43fb-92c4-5cb16399a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `async_ask` instead of `ask` because Juypter notebook already has event loop running.\n",
    "answers = await folder.async_ask(\"What is the author's name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef937e01-a752-4fa3-ae4a-3b8de9bdad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [c.txt] Title: A treatise on the uses of native shrubbery and the children there into, Answer: The author's name is Thomas Babington the Third.\n",
      "1. [e.txt] Title: None, Answer: \n",
      "There isn't enough information to answer the question \"What is the author's name?\" The document does not contain any relevant information about the author or the document's title.\n",
      "\n",
      "2. [d.txt] Title: Another Exciting Story, Answer: The author's name is given as \"Anon\" in the document. This is likely short for \"Anonymous,\" indicating that the true identity of the author is unknown or intentionally withheld.\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c81ae9-8b9b-4f1a-a39a-486ba1ccd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c.txt', 'Title: A treatise on the uses of native shrubbery and the children there into', \"Answer: The author's name is Thomas Babington the Third.\"), ('e.txt', 'Title: None', 'Answer: \\nThere isn\\'t enough information to answer the question \"What is the author\\'s name?\" The document does not contain any relevant information about the author or the document\\'s title.\\n'), ('d.txt', 'Title: Another Exciting Story', 'Answer: The author\\'s name is given as \"Anon\" in the document. This is likely short for \"Anonymous,\" indicating that the true identity of the author is unknown or intentionally withheld.')]\n"
     ]
    }
   ],
   "source": [
    "print(answers.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe904e77-4288-42d5-8904-e85cac1dfb7c",
   "metadata": {},
   "source": [
    "# Answering questions about ScrapeAI's source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c276aac-24fd-4027-8952-ba4f01fca389",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Folder(path='./src/scrapeai', files_endwith=['.py'], client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e3b6823-2739-4b59-bee4-f05d6ca42397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['folder.py', 'client.py', '__init__.py', 'file.py']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b8d447-e602-4c57-98bb-2eb1a1a6c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = await folder.async_ask('What is the purpose of this code?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840e4fe2-2b39-4d4a-84a7-ea52c715cbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0. [folder.py] Title: folder.py, Answer: \n",
       "The purpose of this code is to define a Folder class that represents a directory containing specific types of files. Its main functionalities include:\n",
       "\n",
       "1. Initializing a Folder object with a path, allowed file suffixes, and an API client.\n",
       "2. Retrieving files from the specified folder that match the allowed suffixes.\n",
       "3. Providing a list of filenames in the folder.\n",
       "4. Offering methods to ask questions about the files in the folder using the provided API client, both synchronously and asynchronously.\n",
       "\n",
       "The class enforces specific file types (PDF, TXT, TSV, CSV, MD, PY) and requires an API client for processing questions about the files. It serves as a wrapper for file management and interaction with an external API for file-related queries.\n",
       "\n",
       "1. [client.py] Title: client.py, Answer: \n",
       "The purpose of this code is to create an AnthropicClient class that interacts with the Anthropic API to process and analyze documents. The class has methods to:\n",
       "\n",
       "1. Generate prompts for document analysis\n",
       "2. Send asynchronous requests to the Anthropic API\n",
       "3. Parse responses from the API\n",
       "4. Format and return answers in a user-friendly way\n",
       "\n",
       "The code allows users to submit multiple files and a question, then uses the Anthropic AI model (specifically claude-3-5-sonnet-20240620) to analyze each document and provide answers. It handles asynchronous operations for efficient processing of multiple documents and formats the results into a readable output using the PrettyAnswers class.\n",
       "\n",
       "2. [__init__.py] Title: __init__.py, Answer: \n",
       "The purpose of this code is to serve as an initialization file for a Python package. It imports two specific classes or modules from within the package:\n",
       "\n",
       "1. The Folder class from a \"folder\" module\n",
       "2. The AnthropicClient class from a \"client\" module\n",
       "\n",
       "This __init__.py file makes these imported items available when the package is imported, allowing users to access them directly from the package level rather than having to import from specific submodules.\n",
       "\n",
       "3. [file.py] Title: file.py, Answer: \n",
       "The purpose of this code is to define a File class that can read and extract content from different types of files. Specifically, it handles two scenarios:\n",
       "\n",
       "1. For PDF files (ending with '.pdf'), it uses the PdfReader from the pypdf library to extract text from all pages of the PDF.\n",
       "2. For other file types, it simply reads the content of the file as plain text.\n",
       "\n",
       "The class provides a content() method that returns the extracted or read content as a string, regardless of the file type. This allows for a unified way to access file contents, abstracting away the differences between PDF and non-PDF files."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f40ef-d61b-489d-a992-1d264bf32695",
   "metadata": {},
   "source": [
    "# Answering questions about research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09be7ea-5176-4a76-bbe2-fe88cb486adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Folder(path='./papers', files_endwith=['.pdf'], client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f385d37-40b6-4226-9a88-98601ff5e9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vgg.pdf',\n",
       " 'efficiently_scaling_transformer_inference.pdf',\n",
       " 'attention_is_all_you_need.pdf',\n",
       " 'alexnet.pdf']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc98861-2df5-42ba-8984-41d7b7401082",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = await folder.async_ask('What background information would be good to have before I read this paper?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9423e16-f829-4807-b625-0d2b87deaf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0. [vgg.pdf] Title: Very Deep Convolutional Networks for Large-Scale Image Recognition, Answer: \n",
       "- Basic understanding of convolutional neural networks (ConvNets) and their use in image classification tasks\n",
       "- Familiarity with the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset and competition\n",
       "- Knowledge of previous state-of-the-art ConvNet architectures like AlexNet \n",
       "- Understanding of key ConvNet concepts like convolutional layers, pooling layers, fully connected layers, and network depth\n",
       "- Familiarity with common techniques used in training deep neural networks like data augmentation, dropout, etc.\n",
       "- Basic knowledge of object detection and localization tasks in computer vision\n",
       "\n",
       "Having this background would help provide context for the paper's exploration of very deep ConvNet architectures and their performance on image classification and localization tasks.\n",
       "\n",
       "1. [efficiently_scaling_transformer_inference.pdf] Title: Efficiently Scaling Transformer Inference, Answer: \n",
       "Some helpful background information to have before reading this paper would be:\n",
       "\n",
       "1. Familiarity with Transformer model architecture and inference\n",
       "2. Understanding of model parallelism techniques for large language models\n",
       "3. Knowledge of hardware accelerators like TPUs and their capabilities\n",
       "4. Basics of distributed systems and communication patterns\n",
       "5. Familiarity with common performance metrics for ML inference like latency, throughput, and FLOPS utilization\n",
       "\n",
       "The paper focuses on advanced techniques for efficiently scaling inference of very large Transformer models across many accelerator chips, so having this background would help in understanding the technical details and tradeoffs discussed.\n",
       "\n",
       "2. [attention_is_all_you_need.pdf] Title: Attention Is All You Need, Answer: \n",
       "To read this paper, it would be helpful to have the following background information:\n",
       "\n",
       "1. Understanding of neural network architectures, particularly encoder-decoder models and sequence-to-sequence learning for tasks like machine translation\n",
       "\n",
       "2. Familiarity with attention mechanisms in neural networks\n",
       "\n",
       "3. Knowledge of recurrent neural networks (RNNs) and convolutional neural networks (CNNs), as the paper compares their new model to these approaches\n",
       "\n",
       "4. Basic understanding of natural language processing tasks like machine translation and parsing\n",
       "\n",
       "5. Familiarity with common machine translation metrics like BLEU score\n",
       "\n",
       "6. Some background on recent developments in neural machine translation models\n",
       "\n",
       "Having this background would help in understanding the novel architecture proposed in the paper and how it compares to existing approaches. The paper introduces a new model called the Transformer that relies entirely on attention mechanisms without using recurrence or convolutions.\n",
       "\n",
       "3. [alexnet.pdf] Title: ImageNet Classification with Deep Convolutional Neural Networks, Answer: \n",
       "Some helpful background information to have before reading this paper includes:\n",
       "\n",
       "1. Basic knowledge of convolutional neural networks (CNNs) and deep learning\n",
       "\n",
       "2. Familiarity with image classification tasks and datasets like ImageNet\n",
       "\n",
       "3. Understanding of common deep learning concepts like dropout, ReLUs, data augmentation, etc.\n",
       "\n",
       "4. Basic knowledge of GPU computing for neural networks\n",
       "\n",
       "5. Familiarity with previous state-of-the-art results on ImageNet classification\n",
       "\n",
       "6. Understanding of overfitting challenges in training large neural networks\n",
       "\n",
       "This background would help put the innovations and results presented in the paper in proper context. The paper introduces several novel techniques for training a very large CNN on ImageNet data, so having a foundation in CNNs and image classification is important for following the technical details."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4fa567d-9fa5-4d14-a545-fc6ef1d6c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = await folder.async_ask('What are the key discoveries of this paper? Keep it very succinct.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa42591f-bed9-403b-b861-1b7306902c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0. [vgg.pdf] Title: Very Deep Convolutional Networks for Large-Scale Image Recognition, Answer: \n",
       "The key discoveries of this paper are:\n",
       "\n",
       "1. Increasing the depth of convolutional neural networks to 16-19 layers significantly improves accuracy on image classification tasks.\n",
       "\n",
       "2. Using very small (3x3) convolutional filters throughout the network is effective and allows for increasing depth while controlling the number of parameters.\n",
       "\n",
       "3. The deep networks generalize well to other datasets, outperforming previous state-of-the-art methods on tasks like object classification, localization, and action recognition when used as feature extractors.\n",
       "\n",
       "4. Multi-scale training and evaluation improves performance.\n",
       "\n",
       "5. The best performing models (16 and 19 layers deep) achieved state-of-the-art results on ImageNet classification and localization tasks.\n",
       "\n",
       "1. [efficiently_scaling_transformer_inference.pdf] Title: Efficiently Scaling Transformer Inference, Answer: \n",
       "The key discoveries of this paper are:\n",
       "\n",
       "1. Developed analytical models and partitioning strategies to optimize inference efficiency for large Transformer models across multiple chips.\n",
       "\n",
       "2. Proposed a 2D weight-stationary layout that scales better than 1D layouts as chip count increases.\n",
       "\n",
       "3. Introduced weight-gathered layouts that are more efficient for large batch sizes during prefill.\n",
       "\n",
       "4. Demonstrated multiquery attention with batch sharding enables up to 32x larger context lengths compared to multihead attention.\n",
       "\n",
       "5. Achieved state-of-the-art inference performance on 500B+ parameter models:\n",
       "- 29ms latency per generated token \n",
       "- 76% model FLOPS utilization for large batch prefill\n",
       "- Support for 2048 token context lengths\n",
       "\n",
       "6. Outperformed existing frameworks like FasterTransformer on latency and efficiency metrics across various benchmarks.\n",
       "\n",
       "2. [attention_is_all_you_need.pdf] Title: Attention Is All You Need, Answer: \n",
       "The key discoveries of this paper are:\n",
       "\n",
       "1. The Transformer, a new neural network architecture based entirely on attention mechanisms, without using recurrence or convolutions.\n",
       "\n",
       "2. The Transformer outperforms previous state-of-the-art models on machine translation tasks while being more parallelizable and requiring significantly less training time.\n",
       "\n",
       "3. Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.\n",
       "\n",
       "4. Position-wise feed-forward networks and positional encodings are used to handle sequential information without recurrence.\n",
       "\n",
       "5. The Transformer generalizes well to other tasks like English constituency parsing.\n",
       "\n",
       "The paper demonstrates that self-attention can replace recurrent layers in sequence tasks while providing benefits in computational efficiency and model performance.\n",
       "\n",
       "3. [alexnet.pdf] Title: ImageNet Classification with Deep Convolutional Neural Networks, Answer: \n",
       "The key discoveries of this paper are:\n",
       "\n",
       "1. They trained one of the largest convolutional neural networks to date on the ImageNet dataset, achieving state-of-the-art results.\n",
       "\n",
       "2. They used several novel techniques to improve performance and reduce training time:\n",
       "- ReLU nonlinearity instead of tanh to accelerate training\n",
       "- Training on multiple GPUs \n",
       "- Local response normalization\n",
       "- Overlapping pooling\n",
       "- Data augmentation and dropout to reduce overfitting\n",
       "\n",
       "3. Their network achieved top-5 test error rate of 15.3% on the ImageNet 2012 classification benchmark, compared to 26.2% for the second-best entry.\n",
       "\n",
       "4. They showed that a large, deep convolutional neural network is capable of achieving record-breaking results on a challenging dataset using purely supervised learning.\n",
       "\n",
       "5. They demonstrated the importance of network depth, as removing any middle layer resulted in about 2% loss in top-1 performance."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ffab7-6d04-45b3-9597-5fc612b066fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
